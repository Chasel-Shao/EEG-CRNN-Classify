{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37665f46-3799-4cd5-ab8f-9e321f2a2720",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "from matplotlib.collections import LineCollection\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as T\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.nn.modules.activation import LeakyReLU\n",
    "\n",
    "from torchsummary import summary\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from shutil import rmtree\n",
    "from keras.models import load_model\n",
    "from os.path import join, getctime, basename\n",
    "from models import *\n",
    "from utils import *\n",
    "from data_preprocess import *\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "efdb2f08-b851-4f79-b9a5-3b67901de95a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: {} (7191, 22, 250)\n"
     ]
    }
   ],
   "source": [
    "aug_data = load_prep_data(time=500, debug=False, pooling = True, subsample = 2, average = 2, normalization = False, noise_level = 0.5)\n",
    "\n",
    "x_train = aug_data['x_train']\n",
    "y_train = aug_data['y_train']\n",
    "x_valid = aug_data['x_valid']\n",
    "y_valid = aug_data['y_valid']\n",
    "x_test = aug_data['x_test']\n",
    "y_test = aug_data['y_test']\n",
    "person_train_valid = aug_data['person_train_valid']\n",
    "person_test = aug_data['person_test']\n",
    "X_train_valid = aug_data['X_train_valid']\n",
    "y_train_valid = aug_data['y_train_valid']\n",
    "\n",
    "X_test = x_test\n",
    "input_shape = x_train.shape\n",
    "print(\"x_train.shape: {}\", format(x_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "811740db-99b9-46a2-ab41-3d857087a5cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training set after dimension reshaping: (7191, 250, 22)\n",
      "Shape of validation set after dimension reshaping: (1269, 250, 22)\n",
      "Shape of test set after dimension reshaping: (1772, 250, 22)\n"
     ]
    }
   ],
   "source": [
    "x_train = np.swapaxes(x_train, 1,2)\n",
    "x_valid = np.swapaxes(x_valid, 1,2)\n",
    "x_test = np.swapaxes(X_test, 1,2)\n",
    "print('Shape of training set after dimension reshaping:',x_train.shape)\n",
    "print('Shape of validation set after dimension reshaping:',x_valid.shape)\n",
    "print('Shape of test set after dimension reshaping:',x_test.shape)\n",
    "\n",
    "\n",
    "# Normalize each channel to have mean 0 and std 1\n",
    "def standardize(x):\n",
    "    mean = np.mean(x, axis=1)\n",
    "    var = np.var(x, axis=1)\n",
    "\n",
    "    return (x - mean[:, None]) / np.sqrt(var)[:, None]\n",
    "\n",
    "x_train = standardize(x_train)\n",
    "x_valid = standardize(x_valid)\n",
    "x_test = standardize(x_test)\n",
    "\n",
    "class LoadData(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = torch.Tensor(data)\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index: int):\n",
    "        input_data = self.data[index].permute(1,0)\n",
    "        input_label = self.labels[index]\n",
    "        return (input_data, input_label)\n",
    "    \n",
    "    \n",
    "# train_dataset = LoadData(data=x_train, labels=y_train,)\n",
    "# val_dataset = LoadData(data=x_valid, labels=y_valid,)\n",
    "# train_dl = DataLoader(train_dataset, batch_size=16, num_workers=1, pin_memory=True, shuffle=True)\n",
    "# val_dl = DataLoader(val_dataset, batch_size=16, num_workers=1, pin_memory=True)\n",
    "\n",
    "# data = next(iter(train_dl))\n",
    "# input_data, input_labels = data\n",
    "# print(input_data.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9a2d773-3d9c-444b-ae9d-acee1b7ba59b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class WGANGen(nn.Module):\n",
    "    def __init__(self, noise_dim=100):\n",
    "        super(WGANGen, self).__init__()\n",
    "        # self.scaler = nn.Linear(64 * 50, 64 * 352 * 14)\n",
    "        self.label_emb = nn.Embedding(4, 4)\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=noise_dim + 4, out_features=352 * 14)\n",
    "        self.bnorm1 = nn.BatchNorm1d(352 * 14)\n",
    "        self.relu1 = nn.LeakyReLU(0.3)\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.deconv1 = nn.ConvTranspose1d(352, 176, 5, stride=2, padding=1, output_padding=1, bias=False)\n",
    "        self.bnorm2 = nn.BatchNorm1d(176)\n",
    "        self.relu2 = nn.LeakyReLU(0.3)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.deconv2 = nn.ConvTranspose1d(176, 88, 5, stride=2, padding=1, output_padding=1, bias=False)\n",
    "        self.bnorm3 = nn.BatchNorm1d(88)\n",
    "        self.relu3 = nn.LeakyReLU(0.3)\n",
    "        self.dropout3 = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.deconv3 = nn.ConvTranspose1d(88, 44, 5, stride=2, padding=2, output_padding=1, bias=False)\n",
    "        self.bnorm4 = nn.BatchNorm1d(44)\n",
    "        self.relu4 = nn.LeakyReLU(0.3)\n",
    "        self.dropout4 = nn.Dropout(p=0.5)\n",
    "\n",
    "        self.deconv4 = nn.ConvTranspose1d(44, 22, 5, stride=2, padding=1, output_padding=1, bias=False)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def forward(self, x, labels):\n",
    "        batch_size = x.size(0)  # 动态获取批次大小\n",
    "\n",
    "        h = torch.cat((self.label_emb(labels), x), -1)\n",
    "        # print(h.shape)\n",
    "\n",
    "        h = self.fc1(h)\n",
    "        h = self.bnorm1(h)\n",
    "        h = self.relu1(h)\n",
    "        # h = torch.reshape(h, (64, 352, 14))\n",
    "        h = h.view(batch_size, 352, 14)  # 使用动态批次大小\n",
    "        h = self.dropout1(h)\n",
    "\n",
    "        # print(h.shape)\n",
    "\n",
    "        h = self.deconv1(h)\n",
    "        h = self.bnorm2(h)\n",
    "        h = self.relu2(h)\n",
    "        h = self.dropout2(h)\n",
    "        # print(h.shape)\n",
    "\n",
    "        h = self.deconv2(h)\n",
    "        h = self.bnorm3(h)\n",
    "        h = self.relu3(h)\n",
    "        h = self.dropout3(h)\n",
    "        # print(h.shape)\n",
    "\n",
    "        h = self.deconv3(h)\n",
    "        h = self.bnorm4(h)\n",
    "        h = self.relu4(h)\n",
    "        h = self.dropout4(h)\n",
    "        # print(h.shape)\n",
    "        \n",
    "        h = self.deconv4(h)\n",
    "        h = self.tanh(h)\n",
    "\n",
    "        # print(h.shape)\n",
    "\n",
    "        return h\n",
    "\n",
    "class WGANDis(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(WGANDis, self).__init__()\n",
    "        self.scaler = nn.Linear(4, 250 * 22)\n",
    "        self.label_emb = nn.Embedding(4, 4)\n",
    "\n",
    "        self.conv1 = nn.Conv1d(44, 64, 2, stride=2, padding=0)\n",
    "        self.bnorm1 = nn.BatchNorm1d(64)\n",
    "        self.relu1 = LeakyReLU(0.3)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(64, 128, 2, stride=2, padding=0)\n",
    "        self.bnorm2 = nn.BatchNorm1d(128)\n",
    "        self.relu2 = LeakyReLU(0.3)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(128, 256, 2, stride=2, padding=0)\n",
    "        self.bnorm3 = nn.BatchNorm1d(256)\n",
    "        self.relu3 = LeakyReLU(0.3)\n",
    "\n",
    "        self.conv4 = nn.Conv1d(256, 512, 2, stride=2, padding=0)\n",
    "        self.bnorm4 = nn.BatchNorm1d(512)\n",
    "        self.relu4 = LeakyReLU(0.3)\n",
    "\n",
    "        self.dropout1 = nn.Dropout(p=0.5)\n",
    "        self.fc1 = nn.Linear(7680, 1)\n",
    "    \n",
    "    def forward(self, x, labels):\n",
    "        batch_size = x.size(0)  # 动态获取批次大小\n",
    "        labels = labels.long()\n",
    "        li = self.label_emb(labels)\n",
    "        li = self.scaler(li)\n",
    "        # li = torch.reshape(li, (64, 22, 250))\n",
    "        # 使用动态批次大小进行reshape\n",
    "        li = li.view(batch_size, 22, 250)\n",
    "\n",
    "\n",
    "        h = torch.cat((x, li), 1)\n",
    "\n",
    "        h = self.conv1(h)\n",
    "        h = self.bnorm1(h)\n",
    "        h = self.relu1(h)\n",
    "\n",
    "        h = self.conv2(h)\n",
    "        h = self.bnorm2(h)\n",
    "        h = self.relu2(h)\n",
    "\n",
    "        h = self.conv3(h)\n",
    "        h = self.bnorm3(h)\n",
    "        h = self.relu3(h)\n",
    "\n",
    "        h = self.conv4(h)\n",
    "        h = self.bnorm4(h)\n",
    "        h = self.relu4(h)\n",
    "\n",
    "        h = torch.flatten(h, 1)\n",
    "\n",
    "        h = self.dropout1(h)\n",
    "        h = self.fc1(h)\n",
    "\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93f3f0a1-a49d-4282-ab97-a25b410d4968",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# cuda = True if torch.cuda.is_available() else False\n",
    "# Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "# LongTensor = torch.cuda.LongTensor if cuda else torch.LongTensor\n",
    "# lambda_gp = 10\n",
    "# n_critic = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee26f3d-da55-445c-a3ff-2f5e36593041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_test = WGANGen()\n",
    "PATH = 'data/gan_checkpoint_600.pth'\n",
    "checkpoint = torch.load(PATH)\n",
    "model_test.load_state_dict(checkpoint['generator_state_dict'])\n",
    "model_test.eval()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
