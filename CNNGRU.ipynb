{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Shape of x_train set: (6960, 22, 250)\n",
      "Shape of y_train labels: (6960,)\n",
      "Shape of x_valid set: (1500, 22, 250)\n",
      "Shape of y_valid labels: (1500,)\n",
      "Shape of X_test_prep set: (1772, 22, 250)\n",
      "Shape of y_test_prep labels: (1772,)\n",
      "Shape of y_train labels after categorical conversion: (6960, 4)\n",
      "Shape of y_valid labels after categorical conversion: (1500, 4)\n",
      "Shape of y_test labels after categorical conversion: (1772, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import glob\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from shutil import rmtree\n",
    "from keras.models import load_model\n",
    "from os.path import join, getctime, basename\n",
    "from models import *\n",
    "from utils import *\n",
    "from data_preprocess import load_prep_data\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "aug_data = load_prep_data(time=500, debug=True, onehot=True)\n",
    "x_train = aug_data['x_train']\n",
    "y_train = aug_data['y_train']\n",
    "x_valid = aug_data['x_valid']\n",
    "y_valid = aug_data['y_valid']\n",
    "x_test = aug_data['x_test']\n",
    "y_test = aug_data['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train.shape: {} (6960, 250, 1, 22)\n"
     ]
    }
   ],
   "source": [
    "input_shape = x_train.shape\n",
    "x_train = tf.transpose( tf.expand_dims(x_train, axis=-1), perm=[0, 2, 3, 1])\n",
    "x_valid = tf.transpose( tf.expand_dims(x_valid, axis=-1), perm=[0, 2, 3, 1])\n",
    "\n",
    "print(\"x_train.shape: {}\", format(x_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Layers CNN + GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_16 (Conv2D)          (None, 250, 1, 25)        13775     \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPooli  (None, 84, 1, 25)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_16 (Ba  (None, 84, 1, 25)         100       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 84, 1, 25)         0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 84, 1, 50)         31300     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPooli  (None, 28, 1, 50)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_17 (Ba  (None, 28, 1, 50)         200       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 28, 1, 50)         0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 28, 1, 100)        125100    \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPooli  (None, 10, 1, 100)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_18 (Ba  (None, 10, 1, 100)        400       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_22 (Dropout)        (None, 10, 1, 100)        0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 10, 1, 200)        500200    \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPooli  (None, 4, 1, 200)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " batch_normalization_19 (Ba  (None, 4, 1, 200)         800       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dropout_23 (Dropout)        (None, 4, 1, 200)         0         \n",
      "                                                                 \n",
      " flatten_6 (Flatten)         (None, 800)               0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 40)                32040     \n",
      "                                                                 \n",
      " reshape_4 (Reshape)         (None, 40, 1)             0         \n",
      "                                                                 \n",
      " gru_6 (GRU)                 (None, 40, 64)            12864     \n",
      "                                                                 \n",
      " gru_7 (GRU)                 (None, 16)                3936      \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 4)                 68        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 720783 (2.75 MB)\n",
      "Trainable params: 720033 (2.75 MB)\n",
      "Non-trainable params: 750 (2.93 KB)\n",
      "_________________________________________________________________\n",
      "Model compiled.\n",
      "Epoch 1/50\n",
      "11/11 [==============================] - 5s 353ms/step - loss: 1.3888 - accuracy: 0.2649 - val_loss: 1.3880 - val_accuracy: 0.2293\n",
      "Epoch 2/50\n",
      "11/11 [==============================] - 4s 355ms/step - loss: 1.3742 - accuracy: 0.2951 - val_loss: 1.3699 - val_accuracy: 0.2793\n",
      "Epoch 3/50\n",
      "11/11 [==============================] - 4s 354ms/step - loss: 1.3446 - accuracy: 0.3279 - val_loss: 1.3447 - val_accuracy: 0.3060\n",
      "Epoch 4/50\n",
      "11/11 [==============================] - 4s 353ms/step - loss: 1.3278 - accuracy: 0.3374 - val_loss: 1.3222 - val_accuracy: 0.3320\n",
      "Epoch 5/50\n",
      " 4/11 [=========>....................] - ETA: 2s - loss: 1.3032 - accuracy: 0.3719"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    # Network\n",
    "    'num_inputs': x_train.shape[0],\n",
    "    'input_shape': (input_shape[2], 1, input_shape[1]),\n",
    "    'epochs': 50,\n",
    "    'dropout': 0.5,\n",
    "    'batch_size': 640\n",
    "}\n",
    "CNN2LayerGRU = CNN2LayerGRU()\n",
    "CNN2LayerGRU.build_model(config)\n",
    "history = CNN2LayerGRU.train(x_train, y_train, x_valid, y_valid, config, get_workpath('CNN2LayerGRU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_test_transposed = tf.transpose( tf.expand_dims(x_test, axis=-1), perm=[0, 2, 3, 1])\n",
    "raw = CNN2LayerGRU.evaluate(x_test_transposed, y_test)\n",
    "print(\"Raw Acc result: {}\".format(raw[1]))\n",
    "replace_model_if_better('CNN2LayerGRU', np.mean(raw[1]), CNN2LayerGRU, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 Layers CNN + GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    # Network\n",
    "    'num_inputs': x_train.shape[0],\n",
    "    'input_shape': (input_shape[2], 1, input_shape[1]),\n",
    "    'epochs': 50,\n",
    "    'dropout': 0.5,\n",
    "    'batch_size': 640\n",
    "}\n",
    "CNN4LayerGRU = CNN4LayerGRU()\n",
    "CNN4LayerGRU.build_model(config)\n",
    "history = CNN4LayerGRU.train(x_train, y_train, x_valid, y_valid, config, get_workpath('CNN4LayerGRU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_test_transposed = tf.transpose( tf.expand_dims(x_test, axis=-1), perm=[0, 2, 3, 1])\n",
    "raw = CNN4LayerGRU.evaluate(x_test_transposed, y_test)\n",
    "print(\"Raw Acc result: {}\".format(raw[1]))\n",
    "replace_model_if_better('CNN4LayerGRU', np.mean(raw[1]), CNN4LayerGRU, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
